{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import db_connect\n",
    "from test_data import TestData\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.agent_toolkits.sql import base\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain.agents.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "from prompt_generator import PromptGenerator\n",
    "from examples import FEW_SHOT_EXAMPLES\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"text2sql\"\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_embeddings = OllamaEmbeddings(model=\"llama3:8b\", temperature=0)\n",
    "\n",
    "llama3 = Ollama(model=\"llama3:instruct\", temperature=0)\n",
    "llama3_q8 = Ollama(model=\"llama3:8b-instruct-q8_0\", temperature=0)\n",
    "\n",
    "llama3__with_functions = OllamaFunctions(model=\"llama3:instruct\", format=\"json\")\n",
    "llama3_q8__with_functions = OllamaFunctions(model=\"llama3:8b-instruct-q8_0\", format=\"json\")\n",
    "\n",
    "chatgpt__with_functions = ChatOpenAI(base_url=\"https://api.vsegpt.ru/v1/\", model=\"openai/gpt-3.5-turbo-0125\")\n",
    "chatgpt_embeddings = OpenAIEmbeddings(base_url=\"https://api.vsegpt.ru/v1/\", model=\"openai/gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB with Readonly role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_connect.get_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'John'), (2, 'James'), (3, 'Poul'), (4, 'Christofer'), (5, 'Superman'), (6, 'Donald'), (7, 'Douglas'), (8, 'Dwight'), (9, 'Earl'), (10, 'Edgar'), (11, 'Edmund'), (12, 'Edwin'), (13, 'Elliot'), (14, 'Eric'), (15, 'Ernest'), (16, 'Ethan'), (17, 'Ezekiel'), (18, 'Felix'), (19, 'Franklin'), (20, 'Frederick'), (21, 'Gabriel'), (22, 'Joseph'), (23, 'Joshua'), (24, 'Julian'), (25, 'Alice'), (26, 'Bob'), (27, 'Charlie'), (28, 'David'), (29, 'Emily'), (30, 'Frank'), (31, 'George'), (32, 'Helen'), (33, 'Irene'), (34, 'Jack'), (35, 'Kate'), (36, 'Leo'), (37, 'Mary'), (38, 'Nancy'), (39, 'Oliver'), (40, 'Paul'), (41, 'Qiana'), (42, 'Robert'), (43, 'Samantha'), (44, 'Thomas'), (45, 'Victoria')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"select * from passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt and error handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_generator = PromptGenerator().set_example_selector(\n",
    "        examples=FEW_SHOT_EXAMPLES,\n",
    "        embedding_llm=llama3_embeddings,\n",
    "        k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get agent with provided llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(llm: BaseLanguageModel) -> AgentExecutor:\n",
    "    \"\"\"Create and return agent with provided `llm` model\"\"\"\n",
    "    \n",
    "    return base.create_sql_agent(\n",
    "        llm=llm,\n",
    "        db=db,\n",
    "        agent_type=\"openai-tools\",\n",
    "        prompt=prompt_generator.get_prompt(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Testing an agent with different models and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the names you asked for: 'Alice', 'Bob', 'Charlie', 'Christofer', 'David'\n"
     ]
    }
   ],
   "source": [
    "print(TestData.ANSWER[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_agent(chatgpt__with_functions).invoke({\n",
    "    \"dialect\": \"PostgreSQL\",\n",
    "    \"input\": TestData.QUESTIONS[0],\n",
    "    \"top_k\": \"3\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 names of the passengers, sorted alphabetically, are:\n",
      "1. Alice\n",
      "2. Bob\n",
      "3. Charlie\n",
      "4. Christofer\n",
      "5. David\n"
     ]
    }
   ],
   "source": [
    "print(res[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_agent(llama3__with_functions).invoke({\n",
    "    \"dialect\": \"PostgreSQL\",\n",
    "    \"input\": TestData.QUESTIONS[0],\n",
    "    \"top_k\": \"3\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"query\": \"SELECT  \\\"name\\\" FROM public.\\\"passenger\\\" ORDER BY  \\\"name\\\" LIMIT 5;\" }\n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_agent(llama3_q8__with_functions).invoke({\n",
    "    \"dialect\": \"PostgreSQL\",\n",
    "    \"input\": TestData.QUESTIONS[0],\n",
    "    \"top_k\": \"3\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Query\": \"SELECT passenger.name FROM public.passenger ORDER BY passenger.name LIMIT 5;\"}\n",
      "\n",
      "  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(res[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
