{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import db_connect\n",
    "from test_data import TestData\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.agent_toolkits.sql import base\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "from langchain_community.llms.gigachat import GigaChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"text2sql\"\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3 = Ollama(model=\"llama3:8b\", temperature=0.1)\n",
    "llama3_embeddings = OllamaEmbeddings(model=\"llama3:8b\", temperature=0.1)\n",
    "\n",
    "llama3_inst = Ollama(model=\"llama3:instruct\", temperature=0.1)\n",
    "llama3_inst_q8 = Ollama(model=\"llama3:8b-instruct-q8_0\", temperature=0.1)\n",
    "llama3_inst_fp16 = Ollama(model=\"llama3:8b-instruct-fp16\", temperature=0.1)\n",
    "\n",
    "gigachat = GigaChat(\n",
    "    model=\"GigaChat\",\n",
    "    temperature=0.1,\n",
    "    credentials=os.environ[\"GIGACHAT_AUTH\"], \n",
    "    verify_ssl_certs=False, \n",
    "    scope=\"GIGACHAT_API_PERS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB with Readonly role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_connect.get_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'John'), (2, 'James'), (3, 'Poul'), (4, 'Christofer'), (5, 'Superman'), (6, 'Donald'), (7, 'Douglas'), (8, 'Dwight'), (9, 'Earl'), (10, 'Edgar'), (11, 'Edmund'), (12, 'Edwin'), (13, 'Elliot'), (14, 'Eric'), (15, 'Ernest'), (16, 'Ethan'), (17, 'Ezekiel'), (18, 'Felix'), (19, 'Franklin'), (20, 'Frederick'), (21, 'Gabriel'), (22, 'Joseph'), (23, 'Joshua'), (24, 'Julian'), (25, 'Alice'), (26, 'Bob'), (27, 'Charlie'), (28, 'David'), (29, 'Emily'), (30, 'Frank'), (31, 'George'), (32, 'Helen'), (33, 'Irene'), (34, 'Jack'), (35, 'Kate'), (36, 'Leo'), (37, 'Mary'), (38, 'Nancy'), (39, 'Oliver'), (40, 'Paul'), (41, 'Qiana'), (42, 'Robert'), (43, 'Samantha'), (44, 'Thomas'), (45, 'Victoria')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"select * from passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt and error handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template =\\\n",
    "\"\"\"# Personality\n",
    "You are an expert in PostgreSQL. Answer the question of an ordinary employee who does not know SQL. Please reply in plain text.\n",
    "# Task\n",
    "Please answer the following question to the best of your ability.\n",
    "# Tools\n",
    "Use the following tools to answer:\n",
    "{tools}\n",
    "# Format\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action... \n",
    "(this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "IF YOU WROTE \\\"FINAL ANSWER\\\". THEN DON\\'T WRITE ANYTHING MORE\n",
    "# Start chain of thoughts\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "def err_handle(err):\n",
    "    return \"# Error\\n\" +\\\n",
    "        f\"The previous steps caused an error, here is its text: \\n\\\"{err}\\\"\\n\" +\\\n",
    "        \"DO NOT OUTPUT AN ACTION AND A FINAL ANSWER AT THE SAME TIME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get agent with provided llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(llm: BaseLanguageModel) -> AgentExecutor:\n",
    "    \"\"\"Create and return agent with provided `llm` model\"\"\"\n",
    "    \n",
    "    return base.create_sql_agent(\n",
    "        llm=llm,\n",
    "        db=db,\n",
    "        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        prompt=prompt,\n",
    "        agent_executor_kwargs={\n",
    "            \"handle_parsing_errors\": err_handle,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Testing an agent with different models and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_agent(llama3).batch(TestData.QUESTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'write a joke', 'output': 'Agent stopped due to iteration limit or time limit.'}\n",
      "{'input': 'write a joke about cats', 'output': 'Why did the cat take a selfie? To capture its purr-fect side!'}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..\\\\data\\\\llama3_res.pickle\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
