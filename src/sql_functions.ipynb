{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Functions, based `OllamaFunctions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import db_connect\n",
    "from test_data import TestData\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.agent_toolkits.sql import base\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain.agents import tool\n",
    "\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions, DEFAULT_RESPONSE_FUNCTION, DEFAULT_SYSTEM_TEMPLATE\n",
    "from langchain_experimental.llms.ollama_functions import convert_to_ollama_tool, parse_response\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.agents.output_parsers.openai_functions import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"text2sql\"\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3 = OllamaFunctions(model=\"llama3:8b\", format=\"json\")\n",
    "llama3_inst = OllamaFunctions(model=\"llama3:instruct\", format=\"json\")\n",
    "llama3_inst_q8 = OllamaFunctions(model=\"llama3:8b-instruct-q8_0\", format=\"json\")\n",
    "llama3_inst_fp16 = OllamaFunctions(model=\"llama3:8b-instruct-fp16\", format=\"json\")\n",
    "\n",
    "llama3_text = OllamaFunctions(model=\"llama3:8b-text\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB with Readonly role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_connect.get_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'John'), (2, 'James'), (3, 'Poul'), (4, 'Christofer'), (5, 'Superman'), (6, 'Donald'), (7, 'Douglas'), (8, 'Dwight'), (9, 'Earl'), (10, 'Edgar'), (11, 'Edmund'), (12, 'Edwin'), (13, 'Elliot'), (14, 'Eric'), (15, 'Ernest'), (16, 'Ethan'), (17, 'Ezekiel'), (18, 'Felix'), (19, 'Franklin'), (20, 'Frederick'), (21, 'Gabriel'), (22, 'Joseph'), (23, 'Joshua'), (24, 'Julian'), (25, 'Alice'), (26, 'Bob'), (27, 'Charlie'), (28, 'David'), (29, 'Emily'), (30, 'Frank'), (31, 'George'), (32, 'Helen'), (33, 'Irene'), (34, 'Jack'), (35, 'Kate'), (36, 'Leo'), (37, 'Mary'), (38, 'Nancy'), (39, 'Oliver'), (40, 'Paul'), (41, 'Qiana'), (42, 'Robert'), (43, 'Samantha'), (44, 'Thomas'), (45, 'Victoria')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"select * from passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'WeatherSearch', 'description': 'Call this with an airport code to get the weather at that airport', 'parameters': {'type': 'object', 'properties': {'airport_code': {'description': 'airport code to get weather for', 'type': 'string'}}, 'required': ['airport_code']}}\n"
     ]
    }
   ],
   "source": [
    "class WeatherSearch(BaseModel):\n",
    "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
    "    airport_code: str = Field(description=\"airport code to get weather for\")\n",
    "\n",
    "func = convert_to_openai_function(WeatherSearch)\n",
    "print(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_funcs = llama3_inst_q8.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "        DEFAULT_RESPONSE_FUNCTION\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"# Personality\\nYou are friendly ai assistent.\\n\\n# Todo\\nAnswer the user. If you need, you can use some of this tools.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_prompt = prompt | model_with_funcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(**kwargs):\n",
    "    return f\"451 degrees in {kwargs['unit']} at {kwargs['location']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = { \n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }\n",
    "        return tools[result.tool](**result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_with_funcs | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.batch([\"Hi!\", \"What the weather in New-York?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hello! It's nice to chat with you. What would you like to talk about?\", '451 degrees in celsius at New York, NY']\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
