{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Functions, based `OllamaFunctions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import db_connect\n",
    "from test_data import TestData\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.agent_toolkits.sql import base\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain.agents import tool\n",
    "\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions, DEFAULT_RESPONSE_FUNCTION, DEFAULT_SYSTEM_TEMPLATE\n",
    "from langchain_experimental.llms.ollama_functions import convert_to_ollama_tool, parse_response\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.agents.output_parsers.openai_functions import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"text2sql\"\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3 = OllamaFunctions(model=\"llama3:8b\", format=\"json\")\n",
    "llama3_inst = OllamaFunctions(model=\"llama3:instruct\", format=\"json\")\n",
    "llama3_inst_q8 = OllamaFunctions(model=\"llama3:8b-instruct-q8_0\", format=\"json\")\n",
    "llama3_inst_fp16 = OllamaFunctions(model=\"llama3:8b-instruct-fp16\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB with Readonly role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_connect.get_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'John'), (2, 'James'), (3, 'Poul'), (4, 'Christofer'), (5, 'Superman'), (6, 'Donald'), (7, 'Douglas'), (8, 'Dwight'), (9, 'Earl'), (10, 'Edgar'), (11, 'Edmund'), (12, 'Edwin'), (13, 'Elliot'), (14, 'Eric'), (15, 'Ernest'), (16, 'Ethan'), (17, 'Ezekiel'), (18, 'Felix'), (19, 'Franklin'), (20, 'Frederick'), (21, 'Gabriel'), (22, 'Joseph'), (23, 'Joshua'), (24, 'Julian'), (25, 'Alice'), (26, 'Bob'), (27, 'Charlie'), (28, 'David'), (29, 'Emily'), (30, 'Frank'), (31, 'George'), (32, 'Helen'), (33, 'Irene'), (34, 'Jack'), (35, 'Kate'), (36, 'Leo'), (37, 'Mary'), (38, 'Nancy'), (39, 'Oliver'), (40, 'Paul'), (41, 'Qiana'), (42, 'Robert'), (43, 'Samantha'), (44, 'Thomas'), (45, 'Victoria')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"select * from passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetInformationAboutDatabase(BaseModel):\n",
    "    \"\"\"Gives a comma-separated list of table names from the database.\"\"\"\n",
    "\n",
    "class GetInformationAboutTable(BaseModel):\n",
    "    \"\"\"Gives information about table, e.g. name of columns in table, type of columns, etc\"\"\"\n",
    "    name_of_table: str = Field(description=\"The name of the table you want to get information about.\")\n",
    "\n",
    "\n",
    "get_information_about_database_tool = convert_to_ollama_tool(GetInformationAboutDatabase)\n",
    "get_information_about_table_tool = convert_to_ollama_tool(GetInformationAboutTable)\n",
    "\n",
    "tools_list = [\"get_information_about_database_tool\", \"get_information_about_table_tool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_tables():\n",
    "    return \"Passenger, Employee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_info(table_name: str):\n",
    "    if table_name == \"Passenger\":\n",
    "        return \"Passenger:\\n(passnger_name VARCHAR(60) PRIMARY KEY,\\npassenger_age INT)\"\n",
    "    else:\n",
    "        return \"Employee:\\n(employee_name VARCHAR(60) PRIMARY KEY,\\nemployee_age INT)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools_1 = llama3_inst_q8.bind_tools(\n",
    "    tools=[\n",
    "        get_information_about_database_tool,\n",
    "        DEFAULT_RESPONSE_FUNCTION\n",
    "    ],\n",
    "    tool_choice=\"any\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools_2 = llama3_inst_q8.bind_tools(\n",
    "    tools=[\n",
    "        get_information_about_table_tool\n",
    "    ],\n",
    "    function_calls=\"get_information_about_table_tool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        \"# Personality\\nYou are a friendly AI assistant.\\n\\n\" +\n",
    "        \"# Todo\\nYou should answer the user\\'s question or just have a conversation with them.\" +\n",
    "        \"If user want to talk with you use \\\"__conversational_response\\\"\\n\\n# Tools\\n\" +\n",
    "        DEFAULT_SYSTEM_TEMPLATE\n",
    "    ),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        \"# Personality\\nYou are a friendly AI assistant.\\n\\n\" +\n",
    "        \"# Todo\\nBased on the user's question and the available tables,\" +\n",
    "        \"select the tables you will need, but don't take too many. \" +\n",
    "        \"Please select the minimum required amount.\\n\\n# Tools\\n\" +\n",
    "        DEFAULT_SYSTEM_TEMPLATE\n",
    "    ),\n",
    "    (\"user\", \"User question: {question}\\nAvaible tables:{tables}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_prompt = prompt_1.partial(tools=tools_list) | model_with_tools_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_1(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = { \n",
    "            \"GetInformationAboutDatabase\": get_db_tables,\n",
    "        }\n",
    "        return tools[result.tool](**result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_2(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    elif isinstance(result, str):\n",
    "        return result\n",
    "    else:\n",
    "        tools = { \n",
    "            \"GetInformationAboutTable\": get_table_info,\n",
    "        }\n",
    "        tool_result = tools[result.tool](**result.tool_input)\n",
    "        return (prompt_2.partial(tables=tool_result, tools=tools_list) | model_with_tools_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\"question\": RunnablePassthrough()} | model_with_prompt | OpenAIFunctionsAgentOutputParser() | route_1 #| route_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.batch([\n",
    "    {\"question\": \"Hi\"}, \n",
    "    {\"question\": \"What information is there about the passengers in db?\"}\n",
    "])#, return_exceptions=True)#, config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hello! It's nice to talk to you. Is there something I can help you with or would you like to chat about something in particular?\", \"There is no specific database table for passenger information, but we can extract this information from other tables. For example, we have a 'flights' table which contains the flight numbers and passenger counts. We also have a 'bookings' table where we store the booking details of each passenger. If you want to know more about the passengers in specific flights or bookings, please provide me with more information on what exactly you are looking for.\"]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
